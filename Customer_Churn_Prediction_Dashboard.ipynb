{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0364dbe7",
   "metadata": {},
   "source": [
    "# Import Libraries And Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ea2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoiding package version difference inconsistency for the dashboard\n",
    "import werkzeug\n",
    "from werkzeug.debug.tbtools import DebugTraceback\n",
    "werkzeug.debug.tbtools.get_current_traceback = DebugTraceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dashboard libraries\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# dataset reading-manipıulation library\n",
    "import pandas as pd\n",
    "\n",
    "# label encoding lirary for object type columns of the dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# normalization library for the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# dataset split library for train and test datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# libraries for machine learning algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# evaluation metric libraries for evaluating mahine learning algorithms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# plot libraries to get confusion matrix(heatmap) and scatter plot\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9aa122",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\hasan\\OneDrive\\Masaüstü\\Data_Science\\Data_Science_Projects\\Customer_Churn_Dataset\\data\\all_customer_churn_data.csv\"\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcdf6c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d460b01",
   "metadata": {},
   "source": [
    "# Dataset Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['Gender_Numerical'] = label_encoder.fit_transform(data['Gender'])\n",
    "data['Subscription_Type_Numerical'] = label_encoder.fit_transform(data['Subscription Type'])\n",
    "data['Contract_Length_Numerical'] = label_encoder.fit_transform(data['Contract Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79728887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the daaseet into predictors and target dataset\n",
    "# (also encoded labels and unnecessary columns are dropped)\n",
    "Y = data['Churn'].to_numpy()\n",
    "X = data.drop(columns=['CustomerID', 'Gender', 'Subscription Type', 'Contract Length', 'Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the daataset\n",
    "standard_scaler = StandardScaler()\n",
    "normalized_X = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020054df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into train and test datasets\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(normalized_X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196068c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c509cb62",
   "metadata": {},
   "source": [
    "# Application Of The ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb714f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_X, train_Y)\n",
    "yhat_log_reg = log_reg.predict(test_X)\n",
    "\n",
    "# Logistic Regression Model Evaluation\n",
    "cm_log_reg = confusion_matrix(test_Y, yhat_log_reg)\n",
    "\n",
    "FN_log_reg = cm_log_reg[1][0]\n",
    "TP_log_reg = cm_log_reg[1][1]\n",
    "TN_log_reg = cm_log_reg[0][0]\n",
    "FP_log_reg = cm_log_reg[0][1]\n",
    "\n",
    "type_1_log_reg = FP_log_reg/(TN_log_reg+FP_log_reg)\n",
    "type_2_log_reg = FN_log_reg/(TP_log_reg+FN_log_reg)\n",
    "accuracy_score_log_reg = accuracy_score(test_Y, yhat_log_reg)\n",
    "f1_score_log_reg = f1_score(test_Y, yhat_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d50211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbours(KNN)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(train_X, train_Y)\n",
    "yhat_knn_classifier = knn_classifier.predict(test_X)\n",
    "\n",
    "# K-Nearest Neighbours(KNN) Model Evaluation\n",
    "cm_knn_classifier = confusion_matrix(test_Y, yhat_knn_classifier)\n",
    "\n",
    "FN_knn_classifier = cm_knn_classifier[1][0]\n",
    "TP_knn_classifier = cm_knn_classifier[1][1]\n",
    "TN_knn_classifier = cm_knn_classifier[0][0]\n",
    "FP_knn_classifier = cm_knn_classifier[0][1]\n",
    "\n",
    "type_1_knn_classifier = FP_knn_classifier/(TN_knn_classifier+FP_knn_classifier)\n",
    "type_2_knn_classifier = FN_knn_classifier/(TP_knn_classifier+FN_knn_classifier)\n",
    "accuracy_score_knn_classifier = accuracy_score(test_Y, yhat_knn_classifier)\n",
    "f1_score_knn_classifier = f1_score(test_Y, yhat_knn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naïve Bayes(BernoulliNB)\n",
    "naive_bernoulli = BernoulliNB()\n",
    "naive_bernoulli.fit(train_X, train_Y)\n",
    "yhat_naive_bernoulli = naive_bernoulli.predict(test_X)\n",
    "\n",
    "# Naïve Bayes(BernoulliNB) Model Evaluation\n",
    "cm_naive_bernoulli = confusion_matrix(test_Y, yhat_naive_bernoulli)\n",
    "\n",
    "FN_naive_bernoulli = cm_naive_bernoulli[1][0]\n",
    "TP_naive_bernoulli = cm_naive_bernoulli[1][1]\n",
    "TN_naive_bernoulli = cm_naive_bernoulli[0][0]\n",
    "FP_naive_bernoulli = cm_naive_bernoulli[0][1]\n",
    "\n",
    "type_1_naive_bernoulli = FP_naive_bernoulli/(TN_naive_bernoulli+FP_naive_bernoulli)\n",
    "type_2_naive_bernoulli = FN_naive_bernoulli/(TP_naive_bernoulli+FN_naive_bernoulli)\n",
    "accuracy_score_naive_bernoulli = accuracy_score(test_Y, yhat_naive_bernoulli)\n",
    "f1_score_naive_bernoulli = f1_score(test_Y, yhat_naive_bernoulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "tree_classifier.fit(train_X, train_Y)\n",
    "yhat_tree_classifier = tree_classifier.predict(test_X)\n",
    "\n",
    "# Decision Tree Classifier Model Evaluation\n",
    "cm_tree_classifier = confusion_matrix(test_Y, yhat_tree_classifier)\n",
    "\n",
    "FN_tree_classifier = cm_tree_classifier[1][0]\n",
    "TP_tree_classifier = cm_tree_classifier[1][1]\n",
    "TN_tree_classifier = cm_tree_classifier[0][0]\n",
    "FP_tree_classifier = cm_tree_classifier[0][1]\n",
    "\n",
    "type_1_tree_classifier = FP_tree_classifier/(TN_tree_classifier+FP_tree_classifier)\n",
    "type_2_tree_classifier = FN_tree_classifier/(TP_tree_classifier+FN_tree_classifier)\n",
    "accuracy_score_tree_classifier = accuracy_score(test_Y, yhat_tree_classifier)\n",
    "f1_score_tree_classifier= f1_score(test_Y, yhat_tree_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb28e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rand_forest_classifier = RandomForestClassifier()\n",
    "rand_forest_classifier.fit(train_X, train_Y)\n",
    "yhat_rand_forest_classifier = rand_forest_classifier.predict(test_X)\n",
    "\n",
    "# Random Forest Classifier Model Evaluation\n",
    "cm_rand_forest_classifier = confusion_matrix(test_Y, yhat_rand_forest_classifier)\n",
    "\n",
    "FN_rand_forest_classifier = cm_rand_forest_classifier[1][0]\n",
    "TP_rand_forest_classifier = cm_rand_forest_classifier[1][1]\n",
    "TN_rand_forest_classifier = cm_rand_forest_classifier[0][0]\n",
    "FP_rand_forest_classifier = cm_rand_forest_classifier[0][1]\n",
    "\n",
    "type_1_rand_forest_classifier = FP_rand_forest_classifier/(TN_rand_forest_classifier+FP_rand_forest_classifier)\n",
    "type_2_rand_forest_classifier = FN_rand_forest_classifier/(TP_rand_forest_classifier+FN_rand_forest_classifier)\n",
    "accuracy_score_rand_forest_classifier = accuracy_score(test_Y, yhat_rand_forest_classifier)\n",
    "f1_score_rand_forest_classifier = f1_score(test_Y, yhat_rand_forest_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc06918",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77807485",
   "metadata": {},
   "source": [
    "# Evaluation Metric Results And Best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5fea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics dictionary\n",
    "metrics = {'Model':['Logistic Regression', \n",
    "                    'K-Nearest Neighbours(KNN)', \n",
    "                    'Naïve Bayes(BernoulliNB)', \n",
    "                    'Decision Tree Classifier', \n",
    "                    'Random Forest Classifier'],\n",
    "           \n",
    "           'Type-1 Error':[type_1_log_reg,\n",
    "                           type_1_knn_classifier,\n",
    "                           type_1_naive_bernoulli,\n",
    "                           type_1_tree_classifier,\n",
    "                           type_1_rand_forest_classifier],\n",
    "           \n",
    "           'Type-2 Error':[type_2_log_reg,\n",
    "                           type_2_knn_classifier,\n",
    "                           type_2_naive_bernoulli,\n",
    "                           type_2_tree_classifier,\n",
    "                           type_2_rand_forest_classifier],\n",
    "           \n",
    "           'Accuracy Score':[accuracy_score_log_reg,\n",
    "                             accuracy_score_knn_classifier,\n",
    "                             accuracy_score_naive_bernoulli,\n",
    "                             accuracy_score_tree_classifier,\n",
    "                             accuracy_score_rand_forest_classifier],\n",
    "           \n",
    "           'F1 Score':[f1_score_log_reg,\n",
    "                       f1_score_knn_classifier,\n",
    "                       f1_score_naive_bernoulli,\n",
    "                       f1_score_tree_classifier,\n",
    "                       f1_score_rand_forest_classifier]}\n",
    "\n",
    "\n",
    "# best results of the metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "type_1_best = metrics_df['Type-1 Error'].min()\n",
    "type_2_best = metrics_df['Type-2 Error'].min()\n",
    "accuracy_score_best = metrics_df['Accuracy Score'].max()\n",
    "f1_score_best = metrics_df['F1 Score'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce310a8d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9fb3c",
   "metadata": {},
   "source": [
    "# Plot Functions To Be Used In Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function for the confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    \n",
    "    confusion_matrix_data = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    FN = str(confusion_matrix_data[1][0]) # 1\n",
    "    TP = str(confusion_matrix_data[1][1]) # 2\n",
    "    TN = str(confusion_matrix_data[0][0]) # 3\n",
    "    FP = str(confusion_matrix_data[0][1]) # 4\n",
    "    \n",
    "    # cm_text = [['1', '2'], ['3', '4']]\n",
    "    cm_text = [[FN, TP], [TN, FP]]\n",
    "    \n",
    "    fig = ff.create_annotated_heatmap(confusion_matrix_data,\n",
    "                                      x=['Un-Churned(0)', 'Churned(1)'],\n",
    "                                      y=['Churned(1)', 'Unchurned(0)'],\n",
    "                                      annotation_text=cm_text,\n",
    "                                      colorscale='teal')\n",
    "    fig.update_layout(title_text = model_name+' Confusion Matrix', title_x=0.5)\n",
    "    fig.update_xaxes(title_text='Predicted Values')\n",
    "    fig.update_yaxes(title_text='Actual Values')\n",
    "    fig.update_layout(xaxis={'side': 'bottom'})\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803396d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function for the metric results\n",
    "def plot_information_metrics(metric_type, metrics):\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter(x=metrics['Model'],\n",
    "                                    y=metrics[metric_type],\n",
    "                                    mode=\"markers+lines\")\n",
    "                   )\n",
    "    fig.update_layout(title=metric_type+' Distribution Graph')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e731c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting best fitted models with respect to metric results\n",
    "def best_fitted_model(evaluation_metrics):\n",
    "    \n",
    "    metrics_df = pd.DataFrame(evaluation_metrics)\n",
    "    \n",
    "    type_1 = metrics_df['Type-1 Error'].min()\n",
    "    type_2 = metrics_df['Type-2 Error'].min()\n",
    "    accuracy = metrics_df['Accuracy Score'].max()\n",
    "    f1_score = metrics_df['F1 Score'].max()\n",
    "    \n",
    "    best_results = {'Metrics':['Type-1 Error',\n",
    "                               'Type-2 Error',\n",
    "                               'Accuracy Score',\n",
    "                               'F1 Score'],\n",
    "                    'Best Metric Result':[type_1, type_2, accuracy, f1_score],\n",
    "                    'Model':[metrics_df[metrics_df['Type-1 Error'] == type_1].to_numpy()[0][0],\n",
    "                             metrics_df[metrics_df['Type-2 Error'] == type_2].to_numpy()[0][0],\n",
    "                             metrics_df[metrics_df['Accuracy Score'] == accuracy].to_numpy()[0][0],\n",
    "                             metrics_df[metrics_df['F1 Score'] == f1_score].to_numpy()[0][0]]}\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter(x=best_results['Model'],\n",
    "                                    y=best_results['Best Metric Result'],\n",
    "                                    mode=\"markers\")\n",
    "                   )\n",
    "    fig.update_layout(title='Best Fitted Models Distribution Graph', title_x=0.5)\n",
    "    fig.update_xaxes(title_text='Best Fitted Models With Respect To Evaluation Metrics')\n",
    "    fig.update_yaxes(title_text='Best Fitted Model Evaluation Metric Result')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc4c82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25535f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dopdown menu contents\n",
    "dropdown_menu_list = [{'label':'Logistic Regression Confusion Matrix', 'value':1},\n",
    "                      {'label':'K-Nearest Neighbours(KNN) Confusion Matrix', 'value':2},\n",
    "                      {'label':'Naïve Bayes(BernoulliNB) Confusion Matrix', 'value':3},\n",
    "                      {'label':'Decision Tree Classifier Confusion Matrix', 'value':4},\n",
    "                      {'label':'Random Forest Classifier Confusion Matrix', 'value':5},\n",
    "                      {'label':'Type-1 Error Rate Results', 'value':6},\n",
    "                      {'label':'Type-2 Error Rate Results', 'value':7},\n",
    "                      {'label':'Accuracy Scores', 'value':8},\n",
    "                      {'label':'F1 Scores', 'value':9},\n",
    "                      {'label':'Best Fitted Model(s)', 'value':10}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04fd58",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b5fca6",
   "metadata": {},
   "source": [
    "# Dashboard Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf66a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize app\n",
    "app = dash.Dash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c74946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting app layout\n",
    "app.layout = html.Div(children=[\n",
    "    \n",
    "    # title division\n",
    "    html.Div(html.H1('Predictive Customer Churn Dashboard', \n",
    "                     style={'text-align':'center',\n",
    "                            'font-family':'bahnschrift',\n",
    "                            'color':'#85929E',\n",
    "                            'font-wieght':'bold'}),\n",
    "             style={'backgroundColor':'#D7DBDD',\n",
    "                    'border-radius':'9px'}),\n",
    "    \n",
    "    \n",
    "    # dropdown division\n",
    "    html.Div(dcc.Dropdown(id='dropdown-menu-option',\n",
    "                          options=dropdown_menu_list,\n",
    "                          value=None,\n",
    "                          placeholder='Select an option...'),\n",
    "             style={'backgroundColor':'#D7DBDD',\n",
    "                    'border-radius':'9px',\n",
    "                    'marginLeft':'15%',\n",
    "                    'marginRight':'15%'}),\n",
    "    \n",
    "    # content division\n",
    "    html.Div(children=[\n",
    "        \n",
    "        # information blocks\n",
    "        html.Div(children=[\n",
    "            \n",
    "            # Type-1 Error Rate(Fall-Out),(False Positive Rate-FPR)\n",
    "            html.Div([html.P(\"Type-1 Error Rate\",\n",
    "                             style={'color':'#85929E',\n",
    "                                    'font-wieght':'bold'}),\n",
    "                      html.P(\"-----------------\", id='type-1-block-id')],\n",
    "                     style={'backgroundColor':'#FFFFFF',\n",
    "                            'display':'inline-block',\n",
    "                            'font-family':'bahnschrift',\n",
    "                            'margin':'1%',\n",
    "                            'padding':'1%',\n",
    "                            'border-radius':'9px'}),\n",
    "            \n",
    "            # Type-2 Error Rate(Miss Rate),(False Negative Rate-FNR)\n",
    "            html.Div([html.P(\"Type-2 Error Rate\",\n",
    "                             style={'color':'#85929E',\n",
    "                                    'font-wieght':'bold'}),\n",
    "                      html.P(\"-----------------\", id='type-2-block-id')], \n",
    "                     style={'backgroundColor':'#FFFFFF',\n",
    "                            'display':'inline-block',\n",
    "                            'font-family':'bahnschrift',\n",
    "                            'margin':'1%',\n",
    "                            'padding':'1%',\n",
    "                            'border-radius':'9px'}),\n",
    "            \n",
    "            # accuracy score\n",
    "            html.Div([html.P(\"Accuracy Score\",\n",
    "                             style={'color':'#85929E',\n",
    "                                    'font-wieght':'bold'}),\n",
    "                      html.P(\"-------------\", id='accuracy-score-block-id')], \n",
    "                     style={'backgroundColor':'#FFFFFF',\n",
    "                            'display':'inline-block',\n",
    "                            'font-family':'bahnschrift',\n",
    "                            'margin':'1%',\n",
    "                            'padding':'1%',\n",
    "                            'border-radius':'9px'}),\n",
    "            \n",
    "            # F1 score\n",
    "            html.Div([html.P(\"F1 Score\",\n",
    "                             style={'color':'#85929E',\n",
    "                                    'font-wieght':'bold'}),\n",
    "                     html.P(\"-------\", id='F1-score-block-id')], \n",
    "                     style={'backgroundColor':'#FFFFFF',\n",
    "                            'display':'inline-block',\n",
    "                            'font-family':'bahnschrift',\n",
    "                            'margin':'1%',\n",
    "                            'padding':'1%',\n",
    "                            'border-radius':'9px'})\n",
    "            \n",
    "        ], style={'backgroundColor':'#D7DBDD',\n",
    "                  'border-radius':'9px',\n",
    "                  'text-align':'center'}),\n",
    "        \n",
    "        # graph\n",
    "        html.Div(dcc.Graph(id='plots-id'), \n",
    "                 style={'backgroundColor':'#FFFFFF',\n",
    "                        'marginLeft':'15%',\n",
    "                        'marginRight':'15%',\n",
    "                        'padding':'1%',\n",
    "                        'border-radius':'9px'})\n",
    "        \n",
    "        \n",
    "    ], style={'backgroundColor':'#D7DBDD',\n",
    "              'margin':'2%',\n",
    "              'border-radius':'9px'})\n",
    "    \n",
    "    \n",
    "    \n",
    "], style={'backgroundColor':'#D7DBDD',\n",
    "          'marginTop':'2%',\n",
    "          'marginBottom':'2%',\n",
    "          'marginLeft':'5%',\n",
    "          'marginRight':'5%',\n",
    "          'paddingTop':'1%',\n",
    "          'paddingBottom':'1%',\n",
    "          'border-radius':'9px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    [Output('plots-id', 'figure'),\n",
    "     Output('type-1-block-id', 'children'),\n",
    "     Output('type-2-block-id', 'children'),\n",
    "     Output('accuracy-score-block-id', 'children'),\n",
    "     Output('F1-score-block-id', 'children')],\n",
    "    Input('dropdown-menu-option', 'value')\n",
    ")\n",
    "\n",
    "def evaluation_results(dropdown_menu_option):\n",
    "    \n",
    "    if dropdown_menu_option == None:\n",
    "        fig = plot_confusion_matrix(test_Y, yhat_rand_forest_classifier, ' Best Fitted Model: Random Forest Classifier')\n",
    "        type_1_err_rate = type_1_rand_forest_classifier\n",
    "        type_2_err_rate = type_2_rand_forest_classifier\n",
    "        accuracy = accuracy_score_rand_forest_classifier\n",
    "        f1 = f1_score_rand_forest_classifier\n",
    "    \n",
    "    if dropdown_menu_option == 1:\n",
    "        fig = plot_confusion_matrix(test_Y, yhat_log_reg, 'Linear Regression')\n",
    "        type_1_err_rate = type_1_log_reg\n",
    "        type_2_err_rate = type_2_log_reg\n",
    "        accuracy = accuracy_score_log_reg\n",
    "        f1 = f1_score_log_reg\n",
    "        \n",
    "    if dropdown_menu_option == 2:\n",
    "        fig = plot_confusion_matrix(test_Y, yhat_knn_classifier, 'K-Nearest Neighbours(KNN)')\n",
    "        type_1_err_rate = type_1_knn_classifier\n",
    "        type_2_err_rate = type_2_knn_classifier\n",
    "        accuracy = accuracy_score_knn_classifier\n",
    "        f1 = f1_score_knn_classifier\n",
    "        \n",
    "    if dropdown_menu_option == 3:\n",
    "        fig = plot_confusion_matrix(test_Y, yhat_naive_bernoulli, 'Naïve Bayes(BernoulliNB)')\n",
    "        type_1_err_rate = type_1_naive_bernoulli\n",
    "        type_2_err_rate = type_2_naive_bernoulli\n",
    "        accuracy = accuracy_score_naive_bernoulli\n",
    "        f1 = f1_score_naive_bernoulli\n",
    "        \n",
    "    if dropdown_menu_option == 4:\n",
    "        fig = plot_confusion_matrix(test_Y, yhat_tree_classifier, 'Decision Tree Classifier')\n",
    "        type_1_err_rate = type_1_tree_classifier\n",
    "        type_2_err_rate = type_2_tree_classifier\n",
    "        accuracy = accuracy_score_tree_classifier\n",
    "        f1 = f1_score_tree_classifier\n",
    "        \n",
    "    if dropdown_menu_option == 5:\n",
    "        fig = plot_confusion_matrix(test_Y, yhat_rand_forest_classifier, 'Random Forest Classifier')\n",
    "        type_1_err_rate = type_1_rand_forest_classifier\n",
    "        type_2_err_rate = type_2_rand_forest_classifier\n",
    "        accuracy = accuracy_score_rand_forest_classifier\n",
    "        f1 = f1_score_rand_forest_classifier\n",
    "        \n",
    "    if dropdown_menu_option == 6:\n",
    "        fig = plot_information_metrics('Type-1 Error', metrics)\n",
    "        type_1_err_rate = '----------'\n",
    "        type_2_err_rate = '----------'\n",
    "        accuracy = '----------'\n",
    "        f1 = '----------'\n",
    "        \n",
    "    if dropdown_menu_option == 7:\n",
    "        fig = plot_information_metrics('Type-2 Error', metrics)\n",
    "        type_1_err_rate = '----------'\n",
    "        type_2_err_rate = '----------'\n",
    "        accuracy = '----------'\n",
    "        f1 = '----------'\n",
    "        \n",
    "    if dropdown_menu_option == 8:\n",
    "        fig = plot_information_metrics('Accuracy Score', metrics)\n",
    "        type_1_err_rate = '----------'\n",
    "        type_2_err_rate = '----------'\n",
    "        accuracy = '----------'\n",
    "        f1 = '----------'\n",
    "        \n",
    "    if dropdown_menu_option == 9:\n",
    "        fig = plot_information_metrics('F1 Score', metrics)\n",
    "        type_1_err_rate = '----------'\n",
    "        type_2_err_rate = '----------'\n",
    "        accuracy = '----------'\n",
    "        f1 = '----------'\n",
    "        \n",
    "    if dropdown_menu_option == 10:\n",
    "        fig = best_fitted_model(metrics)\n",
    "        type_1_err_rate = type_1_best\n",
    "        type_2_err_rate = type_2_best\n",
    "        accuracy = accuracy_score_best\n",
    "        f1 = f1_score_best\n",
    "        \n",
    "    return fig, type_1_err_rate, type_2_err_rate, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the dashboard\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(port=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5db45",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
